# Speech Emotion Recognition

# Mentors 
1. Aditya Gupta
2. Arpit Verma

# Teams

**Team 1** 
Anand Patwa
Aryan Singh
Darshit Trevadia
Pushpanshu Tripathi
Shreyasi Mandal
Parth Govil
Aakarshika Singh

**Team 2**
Aarjav Jain
Aryan Agarwal
Rajat Singh
Saaransh Agarwal
Sarthak Kohli
Samrudh BG

**Team 3**
Dheeraj Agarwal
Viplav Patel
Mirge Saurabh Arun
Samriddhi Gupta
Varun Singh
Nitesh Pandey
Rashmi GR

**Team 4**
Anmol Agarwal
Srajan Jain
Rishabh Mukati
Pranav Singh
Sarah Kapoor
Sahil Bansal

**Team 5**
Gaurav Kumar
Tarun Agarwal
Ankit Yadav
Harsh Patel
Gulshan Kumar
Aakash Kumar Bhoi

# Abstract
Detection of emotions is natural for humans, but it is a very difficult task for computers, since accessing the depth behind content is difficult and thatâ€™s what speech emotion recognition (SER) sets out to do. It is a system through which various audio speech files are classified into different emotions such as happy, sad, anger and neutral by computers.

# Objective
In this project, using RAVDESS dataset (which contains around 1500 audio file inputs from 24 different actors (12 male and 12 female) who recorded short audios in 8 different emotions) we will train an NLP-based model which will be able to detect among the 8 basic emotions, as well as the gender of the speaker i.e. Male voice or Female voice. After training we can deploy this model for predicting with live voices.

# Deliverables
1. Learn the basics of Python, ML/DL, NLP, librosa and sklearn; literature review; analyzing the dataset; and feature extraction. 
2. Building and training the model on the training data, followed by testing on test data.
3. Testing the model on live voices and collecting the results.

# Results
The accuracies obtained by different teams  are as follows:

**Team 1**
MLP Model: 63%, CNN Model:73%, LSTM Model: 72%

**Team 2**
MLP Model: 60%, CNN Model:70%, LSTM Model: 60%

**Team 3**
MLP Model: 62%, CNN Model:71%, LSTM Model: 68%

**Team 4**
MLP Model: 71%, CNN Model:78%, LSTM Model: 75%

**Team 5**
MLP Model: 66%, CNN Model:72%, LSTM Model: 66% (Emotion recognition)
MLP Model: 99%, CNN Model:99.5%, LSTM Model: 97% (Gender recognition)


# Demonstration
The video demonstration of the project can be found on the following link:
https://drive.google.com/drive/folders/1t0T0X54XUQ5zpvyOXhztZbLY6y9wd9nN?usp=sharing


# Documentation
The documentation can be accessed at the following link:
https://www.overleaf.com/project/60cc4cd9e461496da6c8ce1c


# Poster
The poster can be viewed at the following link:
https://drive.google.com/file/d/1BMaU_J68fACNt-fm1vPc5KO0vJqWQ2WH/view







